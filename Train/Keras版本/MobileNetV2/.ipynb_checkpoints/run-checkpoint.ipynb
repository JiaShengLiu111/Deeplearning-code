{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 自动加载已修改的python文件\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tensorflow as tf  \n",
    "import numpy as np \n",
    "import utils\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import accuracy_score   \n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'       # 使用第二块GPU（从0开始）\n",
    "\n",
    "pwd = '/notebooks/17_LJS/TbsData/TBS5_加入淡染/'  # 数据路径\n",
    "labels = ['Junk','Negative','Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "配置哪些GPU对Keras模型可见\n",
    "参考至：https://blog.csdn.net/sinat_26917383/article/details/75633754\n",
    "\"\"\"\n",
    "import keras.backend.tensorflow_backend as ktf\n",
    "\n",
    "# GPU 显存自动分配\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.Session(config=config)\n",
    "ktf.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取样本并生成标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小：570131\n",
      "验证集大小：39792\n"
     ]
    }
   ],
   "source": [
    "utils_ = utils.utils()\n",
    "\n",
    "X_train = utils_.getSamplesDir(pwd+\"Train_20W/\",labels)  # 读取训练样本集\n",
    "X_val = utils_.getSamplesDir(pwd+\"Valid/\",labels)  # 读取验证样本集\n",
    "\n",
    "# 随机打乱样本\n",
    "X_train = utils_.myShuffle(X_train)\n",
    "X_val = utils_.myShuffle(X_val)\n",
    "\n",
    "y_train = utils_.geneLabel(X_train,labels)\n",
    "y_val = utils_.geneLabel(X_val,labels)\n",
    "\n",
    "print(\"训练集大小：\"+str(len(y_train)))\n",
    "print(\"验证集大小：\"+str(len(y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计各类样本数量分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别Junk样本数为：\t197332\n",
      "类别Negative样本数为：\t180027\n",
      "类别Positive样本数为：\t192772\n",
      "\n",
      "\n",
      "类别Junk样本数为：\t22743\n",
      "类别Negative样本数为：\t5001\n",
      "类别Positive样本数为：\t12048\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = utils_.countSample(X_train,labels)\n",
    "_ = utils_.countSample(X_val,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析混淆矩阵\n",
    "def analysisConfusionMatrix(ConfusionMatrix):\n",
    "    result = ConfusionMatrix\n",
    "    # 垃圾污染阳性\n",
    "    two = float(sum(result[0][2:3]))/float(sum(result[0][:3])+1e-9)\n",
    "    # 阴性污染阳性\n",
    "    three = float(sum(result[1][2:3]))/float(sum(result[1][:3])+1e-9)\n",
    "    # 阳性丢失\n",
    "    one = float(sum(result[2][:2]))/float(sum(result[2][:3])+1e-9)\n",
    "    print \"阳性丢失：\"+str(round(one,5))+\"  垃圾污染阳性：\"+str(round(two,5))+\"  阴性污染阳性：\"+str(round(three,5))\n",
    "    return one,two,three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义F_beta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析：对于“异常类别”，和查准率相比较，查全率更加重要（查全率高才能降低假阴性率），所以beta应该大于一。 \n",
    "#       但是也不能一味地追求查全率，查准率也有一定的重要性，所以使用使用“异常类别”的f_beta_score系数作为模型评价指标。\n",
    "def F_beta_score(confusionMatrix,beta):  # confusionMatrix二分类任务混淆矩阵,beta为异常类别f1score系数。\n",
    "    tp = confusionMatrix[0][0]\n",
    "    fn = confusionMatrix[0][1]\n",
    "    fp = confusionMatrix[1][0]\n",
    "    tn = confusionMatrix[1][1]\n",
    "    \n",
    "    # 计算“正常类别”的F_beta值\n",
    "    # p_normal = tp/(tp+fp)\n",
    "    # r_normal = tp/(tp+fn)\n",
    "    # f_beta1 = (1+beta1*beta1)*p_normal*r_normal/((beta1*beta1*p_normal)+r_normal)\n",
    "    \n",
    "    # 计算“异常类别”的F_beta值\n",
    "    p_ab = tn/(tn+fn+0.00000001)\n",
    "    r_ab = tn/(tn+fp+0.00000001)\n",
    "    f_beta2 = (1+beta*beta)*p_ab*r_ab/((beta*beta*p_ab)+r_ab+0.00000001)\n",
    "    \n",
    "    return f_beta2\n",
    "\n",
    "# 合并三分类混淆矩阵中“正常类别”和“垃圾类别”，然后调用上述F_beta_score\n",
    "def F_beta_score_MergeNormalAndJunk(confusionMatrix,beta):\n",
    "    newConfusionMatrix = []\n",
    "    tp = confusionMatrix[0][0]+confusionMatrix[0][1]+confusionMatrix[1][0]+confusionMatrix[1][1]\n",
    "    fn = confusionMatrix[0][2]+confusionMatrix[1][2]\n",
    "    fp = confusionMatrix[2][0]+confusionMatrix[2][1]\n",
    "    tn = confusionMatrix[2][2]\n",
    "    \n",
    "    newConfusionMatrix_one = []\n",
    "    newConfusionMatrix_one.append(tp)\n",
    "    newConfusionMatrix_one.append(fn)\n",
    "    \n",
    "    newConfusionMatrix_two = []\n",
    "    newConfusionMatrix_two.append(fp)\n",
    "    newConfusionMatrix_two.append(tn)\n",
    "    \n",
    "    newConfusionMatrix.append(newConfusionMatrix_one)\n",
    "    newConfusionMatrix.append(newConfusionMatrix_two)\n",
    "    \n",
    "    return F_beta_score(newConfusionMatrix,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成训练集子集，用于分析模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别Junk样本数为：\t13685\n",
      "类别Negative样本数为：\t12677\n",
      "类别Positive样本数为：\t13430\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_evalua,y_train_evalua=utils_.randomCropSample(X_train,y_train,len(X_val))\n",
    "_ = utils_.countSample(X_train_evalua,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义模型网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Build\n",
    "import tensorflow as tf  \n",
    "from IPython.display import display_html\n",
    "from keras import backend as K\n",
    "import Config as cfg0\n",
    "\n",
    "def trainFun(model,utils,dataenhance,reDir='info/info.txt'):\n",
    "    utils.printRd(\"\",reDir,\"w+\")  # 清空重定向文件 \n",
    "    # tf.reset_default_graph()    # 清空运行图\n",
    "    batch_size = cfg0.batch_size        \n",
    "\n",
    "    # 表示训练多少个batch对应一epoch \n",
    "    epoch = int(len(X_train)/batch_size+1e-9)  \n",
    "    # 设置训练轮数\n",
    "    STEPS = int(epoch*cfg0.epochs)  \n",
    "    print \"the number of total batch:\"+str(STEPS)\n",
    "\n",
    "    with tf.Session(config = config) as sess:    \n",
    "        sess.run(tf.global_variables_initializer())  # 初始化变量  \n",
    "        \n",
    "        # 判断是否加载与训练模型\n",
    "        if cfg0.loadmodel_path!=None:\n",
    "            model = load_model(cfg0.loadmodel_path+cfg0.loadmodel_name)\n",
    "\n",
    "        val_accuracy_list = []  # 绘制验证集准确率变化曲线\n",
    "        val_f1_list = []  # 绘制验证集f1_score变化曲线\n",
    "        train_accuracy_list = []  # 绘制训练集准确率变化曲线\n",
    "        cost_list_train = []\n",
    "        cost_list_val = []\n",
    "\n",
    "        val_f_beta_score_max = -1 # 记录val_f1的最大值\n",
    "        val_f1_max = -1 # 记录val_f1的最大值\n",
    "        for i in range(0,STEPS):   # 表示从索引为start开始训练样本（主要是为了均衡二次训练时样本被训练的机会）\n",
    "            utils.printRd(\"............................第\"+str(i)+\"个batch............................\",reDir)  \n",
    "            # 首先进行学习率指数衰减计算\n",
    "            # model = utils_.lr_exponential_decay(model,i,cfg0.lr_decay_step,cfg0.lr_decay_rate)\n",
    "            # calculate learning rate\n",
    "#             if i!=0 and i%decay_step==0:\n",
    "#                 lr = K.get_value(model.optimizer.lr)  # 获取模型当前学习率\n",
    "#                 K.set_value(model.optimizer.lr, lr*decay_rate)  # set new lr b\n",
    "            \n",
    "            \n",
    "            if i%(int(cfg0.saveStepEpochRate*epoch))==0 and (i!=0 or cfg0.firstPred==True):  # 判断在进行训练之前是否进行预测。 \n",
    "                # 记录“训练集准确率”、“验证集准确率”、“验证集F1”  \n",
    "                train_predicts,_ = utils.predict_keras(model,X_train_evalua,batch_size,dataenhance,reDir)  \n",
    "                val_predicts,_ = utils.predict_keras(model,X_val,batch_size,dataenhance,reDir)\n",
    "                \n",
    "                # 求真实标签\n",
    "                train_evalua_realLabel = utils.onehot2realLabel(y_train_evalua)\n",
    "                train_predicts_realLabel = utils.onehot2realLabel(train_predicts,utils.countSample(X_train,labels)) \n",
    "                \n",
    "                val_realLabel = utils.onehot2realLabel(y_val)\n",
    "                val_predicts_realLabel = utils.onehot2realLabel(val_predicts,utils.countSample(X_train,labels))\n",
    "\n",
    "                # 计算“准确率”等 \n",
    "                train_accuracy = accuracy_score(train_evalua_realLabel,train_predicts_realLabel, normalize=True)\n",
    "                val_accuracy = accuracy_score(val_realLabel,val_predicts_realLabel, normalize=True)\n",
    "                val_f1 = f1_score(val_realLabel,val_predicts_realLabel,average=\"macro\") \n",
    "                train_confusion_matrix = confusion_matrix(train_evalua_realLabel,train_predicts_realLabel)\n",
    "                val_confusion_matrix = confusion_matrix(val_realLabel,val_predicts_realLabel)\n",
    "                \n",
    "                # 修改模型评价指标为“异常类别”的f_beta_score\n",
    "                val_f_beta_score = F_beta_score_MergeNormalAndJunk(val_confusion_matrix,beta=1)  # beta=2，表示“异常类别”查全率的重要性是查准率的4倍\n",
    "                \n",
    "                # 训练集交叉熵\n",
    "                cross_entropy_train = sess.run(-tf.reduce_mean(y_train_evalua*tf.log(tf.clip_by_value(train_predicts,1e-10,1.0))))\n",
    "                cross_entropy_val = sess.run(-tf.reduce_mean(y_val*tf.log(tf.clip_by_value(val_predicts,1e-10,1.0))))\n",
    "                \n",
    "                # 对各个参数只保留五位小数（后面的位四舍五入处理）\n",
    "                train_accuracy = round(train_accuracy,5)\n",
    "                val_accuracy = round(val_accuracy,5)\n",
    "                cross_entropy_train = round(cross_entropy_train,5)\n",
    "                cross_entropy_val = round(cross_entropy_val,5)\n",
    "                val_f1 = round(val_f1,5) \n",
    "                val_f_beta_score = round(val_f_beta_score,5)\n",
    "\n",
    "                utils.printRd(\"训练集混淆矩阵为：\",reDir)\n",
    "                utils.printRd(np.array(train_confusion_matrix),reDir)\n",
    "                utils.printRd(analysisConfusionMatrix(train_confusion_matrix),reDir)\n",
    "                utils.printRd(\"验证集混淆矩阵为：\",reDir)\n",
    "                utils.printRd(np.array(val_confusion_matrix),reDir)\n",
    "                utils.printRd(analysisConfusionMatrix(val_confusion_matrix),reDir)\n",
    "\n",
    "                utils.printRd(\"第\"+str(i)+\"次迭代：\"+\"train_accuracy=\"+str(train_accuracy)+\" val_accuracy=\"+str(val_accuracy)+\" cost=\"+str(cross_entropy_train)+\" val_f1:\"+str(val_f1)+ \" val_f_beta_score:\"+str(val_f_beta_score),reDir) \n",
    " \n",
    "                train_accuracy_list.append(train_accuracy)\n",
    "                val_accuracy_list.append(val_accuracy)\n",
    "                val_f1_list.append(val_f1) \n",
    "                cost_list_train.append(cross_entropy_train)\n",
    "                cost_list_val.append(cross_entropy_val)\n",
    "                lists = [val_accuracy_list,val_f1_list,train_accuracy_list]\n",
    "                names = [\"val_accuracy\",\"val_f1\",\"train_accuracy\"]\n",
    "                utils.showPerformOrCostCurve(lists,names,os.path.dirname(reDir)+'/perform.jpg') # 绘制准确率/F1分数\n",
    "                lists = [cost_list_train,cost_list_val]\n",
    "                names = [\"train_cost\",\"val_cost\"]\n",
    "                utils.showPerformOrCostCurve(lists,names,os.path.dirname(reDir)+'/cost.jpg') # 绘制损失函数\n",
    "                \n",
    "                if val_f1>val_f1_max:\n",
    "                    val_f1_max = val_f1\n",
    "                    utils.printRd(\"val_f1最大值更新：\"+str(val_f1_max),reDir)\n",
    "\n",
    "                # 修改模型保存条件为：每次epoch判断一次val_f1是否大于val_f1_max,假如满足条件就保存一次模型\n",
    "                if val_f_beta_score>val_f_beta_score_max:  # 这样做也就相当于earlystoping。\n",
    "                    # vgg.save_npy(sess,pwd+'jsL/keras_model/vggPara-save_train_l2正则化解决过拟合.npy')     \n",
    "                    # 因为模型中使用了BN层，参数无法提取，所以替换使用Saver.save函数保存模型\n",
    "                    # saver.save(sess, cfg0.saveModelPath)  # 保存模型  \n",
    "                    model.save(cfg0.saveModelPath)\n",
    "                    val_f_beta_score_max = val_f_beta_score\n",
    "                    utils.printRd(\"model saved!\",reDir)\n",
    "                else:\n",
    "                    utils.printRd(\"model not saved!\",reDir)  \n",
    "\n",
    "            # 每次选取batch_size个样本进行训练\n",
    "            # 梯度下降训练模型参数\n",
    "            start = (i*batch_size)%len(X_train)\n",
    "            end = min(start+batch_size,len(X_train)) \n",
    "            xxx = dataenhance.getMiniBatch4Train(X_train[start:end])\n",
    "            # sess.run(train, feed_dict={model.inputs: xxx, model.labels: y_train[start:end], model.is_training: True})  \n",
    "            yyy = np.array(y_train[start:end])\n",
    "            model.train_on_batch(xxx,yyy,class_weight=None, sample_weight=None)\n",
    "        display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "        sess.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:0.01\n",
      "x:0.0094\n",
      "x:0.008836\n",
      "x:0.00830584\n",
      "x:0.0078074896\n",
      "x:0.007339040224\n",
      "x:0.00689869781056\n",
      "x:0.00648477594193\n",
      "x:0.00609568938541\n",
      "x:0.00572994802229\n",
      "x:0.00538615114095\n",
      "x:0.00506298207249\n",
      "x:0.00475920314814\n",
      "x:0.00447365095925\n",
      "x:0.0042052319017\n",
      "x:0.0039529179876\n",
      "x:0.00371574290834\n",
      "x:0.00349279833384\n",
      "x:0.00328323043381\n",
      "x:0.00308623660778\n",
      "x:0.00290106241131\n",
      "x:0.00272699866664\n",
      "x:0.00256337874664\n",
      "x:0.00240957602184\n"
     ]
    }
   ],
   "source": [
    "x  = cfg0.lr\n",
    "for i in range(24):  \n",
    "    print \"x:\"+str(x)\n",
    "    x = x*cfg0.lr_decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of total batch:356320\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8818524d93b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataenhance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataEnhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNet_V2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutils_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataenhance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1908089ecf4c>\u001b[0m in \u001b[0;36mtrainFun\u001b[0;34m(model, utils, dataenhance, reDir)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveStepEpochRate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcfg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstPred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 判断在进行训练之前是否进行预测。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# 记录“训练集准确率”、“验证集准确率”、“验证集F1”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mtrain_predicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m                                                  \u001b[0mX_train_evalua\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataenhance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mval_predicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m                                                \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataenhance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'prob'"
     ]
    }
   ],
   "source": [
    "reDir = cfg0.train_reDir\n",
    "dataenhance = utils.DataEnhance(image_h = 224,image_w = 224)\n",
    "model = Build.MobileNet_V2().build()\n",
    "trainFun(model,utils_,dataenhance,reDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
